Product Requirements Document (PRD): Portfolio Risk Analyzer
1. Executive Summary
This document outlines the specifications for a Streamlit-based "Portfolio Risk Analyzer" tool. The application serves as a proof-of-concept demonstrating quantitative finance skills and risk management concepts through an interactive web interface.
2. Technology Stack
â€¢	Frontend Framework: Streamlit (v1.22.0+)
â€¢	Backend Language: Python (3.9+)
â€¢	Core Libraries: 
o	pandas (1.5.0+): Data manipulation and analysis
o	numpy (1.23.0+): Numerical computing
o	plotly (5.13.0+): Interactive visualizations
o	scipy (1.10.0+): Statistical calculations
o	openpyxl (3.1.0+): Excel file handling
3. Data Structures & Input Formats
3.1 User Portfolio Input
File Upload Format:
â€¢	CSV or Excel file with minimum required columns: 
o	Ticker: String, valid stock/ETF symbol (e.g., "AAPL", "SPY")
o	Weight: Float, allocation percentage in decimal form (e.g., 0.30 for 30%)
CSV Structure Example:
Ticker,Weight
AAPL,0.25
MSFT,0.25
VTI,0.20
BND,0.15
GLD,0.15
Template File:
â€¢	System must provide a downloadable template with the exact required format
â€¢	Template should include examples with placeholder values
3.2 Historical Returns Data
Source File: monthly_returns.csv
Format Specification:
â€¢	First row (header): Contains ticker symbols starting from column B
â€¢	Column A: Contains dates (mm/dd/yyyy format) representing the start of each month
â€¢	All other cells: Monthly return values as decimals (e.g., 0.05 for 5% return)
Data Validation:
â€¢	System must validate that tickers in user portfolio exist in the monthly returns dataset
â€¢	System must validate date range completeness for accurate calculations
4. Core Functionality
4.1 Portfolio Input Processing
User Flow:
1.	Landing page presents upload option, template download, and portfolio generator
2.	User selects input method (upload CSV/Excel or generate random portfolio)
3.	System validates input data and displays portfolio summary
4.	If validation fails, system shows specific error messages and suggests corrections
Random Portfolio Generator:
â€¢	Generate random weights for 5-10 tickers selected from available tickers in monthly_returns.csv
â€¢	Weights must sum to 1.0 (normalized)
Validation Requirements:
â€¢	Sum of weights must be within tolerance of 1.0 (default tolerance: Â±0.01)
â€¢	All tickers must exist in the historical returns data
â€¢	No missing or malformed data in required fields
â€¢	Proper handling of case sensitivity in ticker symbols
4.2 Data Processing Pipeline
Historical Data Processing:
1.	Filter monthly_returns.csv to include only tickers in the user's portfolio
2.	Process data for multiple time periods (1, 3, and 5 years)
3.	Calculate weighted returns based on portfolio allocation
Performance Optimization:
â€¢	Implement caching using @st.cache_data for data loading operations
â€¢	Consider chunking for large datasets to prevent memory issues
â€¢	Implement progress indicators for operations taking >1 second
4.3 Risk Metrics Calculation
Annualized Volatility:
â€¢	Formula: Ïƒ_annual = Ïƒ_monthly Ã— âˆš12
â€¢	Where Ïƒ_monthly is the standard deviation of monthly returns
â€¢	Implementation: portfolio_volatility = np.std(portfolio_returns) * np.sqrt(12)
Maximum Drawdown:
â€¢	Formula: MaxDD = (Trough Value - Peak Value) / Peak Value
â€¢	Implementation: 
â€¢	def calculate_max_drawdown(returns):    # Convert returns to cumulative returns    cum_returns = (1 + returns).cumprod()    # Calculate running maximum    running_max = np.maximum.accumulate(cum_returns)    # Calculate drawdown    drawdown = (cum_returns - running_max) / running_max    # Return the minimum drawdown (maximum loss)    return drawdown.min()
Value at Risk (VaR):
â€¢	Historical VaR Calculation: 
â€¢	def calculate_historical_var(returns, confidence_level=0.95):    # Sort returns from worst to best    sorted_returns = np.sort(returns)    # Find the index at the confidence level    index = int(len(sorted_returns) * (1 - confidence_level))    # Return the value at that index    return sorted_returns[index]
â€¢	Support both 95% and 99% confidence levels
â€¢	Report both absolute VaR (dollar amount) and percentage VaR
Correlation Matrix:
â€¢	Calculate using both Pearson and Spearman methods
â€¢	Allow user to toggle between correlation methods
â€¢	Implementation: correlation_matrix = returns_df.corr(method='pearson')
Sharpe Ratio:
â€¢	Formula: (Râ‚š - Rá¶ ) / Ïƒâ‚š
â€¢	Where: 
o	Râ‚š = Portfolio return (annualized)
o	Rá¶  = Risk-free rate (default: 0.02 or 2%)
o	Ïƒâ‚š = Portfolio standard deviation (annualized)
â€¢	Implementation: 
â€¢	def calculate_sharpe_ratio(returns, risk_free_rate=0.02):    annual_return = np.mean(returns) * 12    annual_volatility = np.std(returns) * np.sqrt(12)    return (annual_return - risk_free_rate) / annual_volatility
4.4 Scenario Analysis
Market Drop Simulation:
â€¢	User inputs percentage drop in reference index (e.g., SPY)
â€¢	System calculates beta for each holding relative to reference index
â€¢	Formula: Portfolio impact = Î£(Asset Weight Ã— Asset Beta Ã— Market Drop)
â€¢	Implementation: 
â€¢	def calculate_beta(asset_returns, market_returns):    covariance = np.cov(asset_returns, market_returns)[0, 1]    market_variance = np.var(market_returns)    return covariance / market_variance
Historical Event Replay:
â€¢	Predefined crisis periods: 
o	COVID-19 Crash: 2020-02-01 to 2020-04-30
o	2022 Bear Market: 2022-01-01 to 2022-10-31
â€¢	System filters historical returns for selected period
â€¢	Applies actual returns from that period to current portfolio weights
â€¢	Reports total drawdown and recovery time (if within data range)
5. UI/UX Specifications
5.1 Application Structure
Navigation Components:
â€¢	Sidebar: Primary navigation between major sections
â€¢	Tabs: Secondary navigation within sections
Main Sections:
1.	Dashboard/Overview:
o	Portfolio summary
o	Key risk metrics at a glance
o	Asset allocation visualization
2.	Risk Analysis:
o	Detailed risk metrics with explanations
o	Historical performance charts
o	Correlation heatmap
3.	Scenario Testing:
o	Market drop simulator
o	Historical event simulator
o	Interest rate shock simulator
4.	Help & Documentation:
o	Metric definitions
o	Usage instructions
o	Data sources information
5.2 Interactive Elements
Charts & Visualizations:
â€¢	Portfolio Composition: Pie or donut chart
â€¢	Risk Metrics Comparison: Radar chart
â€¢	Correlation Heatmap: Interactive heatmap with tooltip values
â€¢	Historical Performance: Line chart with adjustable time window
â€¢	Drawdown Chart: Waterfall chart showing maximum drawdowns
Input Controls:
â€¢	Confidence level slider for VaR (95% to 99%)
â€¢	Dropdown for correlation method (Pearson/Spearman)
â€¢	Market drop percentage input (-5% to -50%)
â€¢	Historical event selection dropdown
â€¢	Interest rate change slider (-200 to +200 bps)
5.3 Educational Components
Tooltips & Explanations:
â€¢	Hoverable "?" icons next to each metric with tooltip explanations
â€¢	Modal dialogs for detailed metric explanations with formulas
â€¢	Contextual hints for interpretation of results
Example:
st.markdown("### Value at Risk (VaR) ðŸ“Š")
col1, col2 = st.columns([3, 1])
with col1:
    var_confidence = st.slider("Confidence Level", 90, 99, 95, 1, format="%d%%")
with col2:
    st.info("VaR represents the minimum expected loss at a given confidence level over a specific time horizon.")
6. Error Handling & Edge Cases
6.1 Data Validation Errors
Portfolio Input:
â€¢	Weights don't sum to 1.0: Show warning with exact deviation
â€¢	Tickers not found: List specific missing tickers
â€¢	Malformed input: Highlight specific rows/columns with issues
Monthly Returns Data:
â€¢	Missing data points: Identify gaps and recommend date range adjustment
â€¢	Insufficient history: Warn if selected period exceeds available data
6.2 Calculation Edge Cases
â€¢	Empty portfolio: Prevent calculation and show appropriate message
â€¢	Extreme values: Handle outliers in returns data
â€¢	Zero variance assets: Handle division by zero in beta/correlation calculations
â€¢	Negative weights: Flag short positions and adjust calculations accordingly
6.3 Error Message Standards
â€¢	Technical Error: Include error code and specific details
â€¢	User Error: Provide clear guidance on how to fix the issue
â€¢	Data Error: Identify specific data points that are problematic
